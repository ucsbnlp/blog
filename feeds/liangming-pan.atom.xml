<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>UCSB NLP Blog - Liangming Pan</title><link href="nlp.cs.ucsb.edu/blog/" rel="alternate"></link><link href="nlp.cs.ucsb.edu/blog/feeds/liangming-pan.atom.xml" rel="self"></link><id>nlp.cs.ucsb.edu/blog/</id><updated>2021-08-01T17:30:00-07:00</updated><entry><title>Zero-shot Fact Verification by Claim Generation</title><link href="nlp.cs.ucsb.edu/blog/zero-shot-fact-verification-by-claim-generation.html" rel="alternate"></link><published>2021-08-01T17:30:00-07:00</published><updated>2021-08-01T17:30:00-07:00</updated><author><name>Liangming Pan</name></author><id>tag:None,2021-08-01:nlp.cs.ucsb.edu/blog/zero-shot-fact-verification-by-claim-generation.html</id><summary type="html">&lt;p&gt;ACL-IJCNLP 2021 Paper "Zero-shot Fact Verification by Claim Generation"&lt;/p&gt;</summary><content type="html">&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Fact verification&lt;/strong&gt; aims to validate a claim in the context of evidence. Given a claim &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{C}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.05834em;"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and a piece of evidence &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{P}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.08222em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as inputs, a fact verification model &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;F&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{F}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.09931em;"&gt;F&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; predicts a label &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;Y&lt;/mi&gt;&lt;mo&gt;∈&lt;/mo&gt;&lt;mo stretchy="false"&gt;{&lt;/mo&gt;&lt;mtext mathvariant="monospace"&gt;supported&lt;/mtext&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mtext mathvariant="monospace"&gt;refuted&lt;/mtext&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mtext mathvariant="monospace"&gt;NEI&lt;/mtext&gt;&lt;mo stretchy="false"&gt;}&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{Y} \in \{\texttt{supported}, \texttt{refuted}, \texttt{NEI} \}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.78055em;vertical-align:-0.09722em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.08222em;"&gt;Y&lt;/span&gt;&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2777777777777778em;"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;∈&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.2777777777777778em;"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;{&lt;/span&gt;&lt;span class="mord text"&gt;&lt;span class="mord texttt"&gt;supported&lt;/span&gt;&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord text"&gt;&lt;span class="mord texttt"&gt;refuted&lt;/span&gt;&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord text"&gt;&lt;span class="mord texttt"&gt;NEI&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose"&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; to verify whether &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{C}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.05834em;"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is supported, refuted, or can not be verified by the information in &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{P}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.08222em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. Fact verification task has attracted growing interest with the rise in disinformation in news and social media. Rapid progress has been made by training large neural models on the &lt;a href="https://arxiv.org/abs/1803.05355"&gt;FEVER dataset&lt;/a&gt;, containing more than 100K human-crafted (evidence, claim) pairs based on Wikipedia.&lt;/p&gt;
&lt;p&gt;Fact verification is demanded in many domains, including news articles, social media, and scientific documents. However, it is not realistic to assume that large-scale training data is available for every new domain that requires fact verification. Creating training data by asking humans to write claims and search for evidence to support/refute them can be extremely costly. &lt;/p&gt;
&lt;h4&gt;Zero/Few-shot Fact Verification&lt;/h4&gt;
&lt;p&gt;Could we train a good fact checking model without human annotation? &lt;strong&gt;We explore this possibility of automatically generating large-scale (evidence, claim, label) data to train the fact verification model.&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;As illustrated in Figure 1 below, we propose a simple yet general framework &lt;strong&gt;Question Answering for Claim Generation (QACG)&lt;/strong&gt; to generate three types of claims from any given evidence: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Claims that are supported by the evidence&lt;/li&gt;
&lt;li&gt;Claims that are refuted by the evidence&lt;/li&gt;
&lt;li&gt;Claims that the evidence does Not have Enough Information (NEI) to verify&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Zero-shot Fact Verification&lt;/strong&gt;: We assume no human-annotated training example is available. We only use the generated (evidence, claim, label) data are used to train the fact verification model. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Few-shot Fact Verification&lt;/strong&gt;: We assume only a few human-labeled (evidence, claim) pairs are available. We first train the fact verification model with the generated data. Then we fine-tune the model with the limited amount of human-labeled data. &lt;/p&gt;
&lt;h5&gt;Figure 1&lt;/h5&gt;
&lt;p&gt;&lt;img alt="zero-shot-fact-verification" class="img-fluid" src="images/2108/zero-shot-fact-verification.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Our zero-shot fact verification framework.&lt;/em&gt;&lt;/p&gt;
&lt;h4&gt;Main Observations&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Reducing Human Labor&lt;/strong&gt;: pretraining the fact verification model with generated claims greatly reduces the demand for in-domain human annotation. 
- &lt;strong&gt;Zero-shot Setting&lt;/strong&gt;: Although we do not use any human-labeled training examples, the model achieves over 70% of the F1 performance of a fully-supervised setting. 
- &lt;strong&gt;Few-shot Setting&lt;/strong&gt;: By fine-tuning the model with only 100 labeled examples, we further close the performance gap, achieving 89.1% of fully-supervised performance. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Improving Robustness&lt;/strong&gt;: When evaluating the model on an unbiased test set for FEVER, we find that training with generated claims also produces a more robust fact verification model. &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Claim Generation Model&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;As illustrated in Figure 2 below, our claim generation model QACG has two major components: &lt;/p&gt;
&lt;h4&gt;Question Generator&lt;/h4&gt;
&lt;p&gt;A &lt;strong&gt;Question Generator&lt;/strong&gt; &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;G&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{G}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.78055em;vertical-align:-0.09722em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal" style="margin-right:0.0593em;"&gt;G&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; takes as input an evidence &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and a text span &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; from the given evidence and aims to generate a question &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;Q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; with &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as the answer. We implement this with the &lt;a href="https://arxiv.org/abs/1910.13461"&gt;BART model&lt;/a&gt;, a large transformer-based sequence-to-sequence model pretrained on 160GB of text. The model is finetuned on the SQuAD dataset processed by &lt;a href="https://arxiv.org/abs/1704.01792"&gt;Zhou et al. (2017)&lt;/a&gt;, where the model encodes the concatenation of the SQuAD passage and the answer text and then learns to decode the question. &lt;/p&gt;
&lt;h4&gt;QA-to-Claim model&lt;/h4&gt;
&lt;p&gt;The &lt;strong&gt;QA-to-Claim model&lt;/strong&gt; &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi mathvariant="script"&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;\mathcal{M}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathcal"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; takes as inputs &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;Q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.8777699999999999em;vertical-align:-0.19444em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;Q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;A&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;A&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, and outputs the declarative sentence &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;C&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;C&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.07153em;"&gt;C&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; for the &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;(Q, A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathdefault"&gt;Q&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;A&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; pair. We also treat this as a sequence-to-sequence problem and finetune the BART model on the &lt;a href="https://arxiv.org/abs/1809.02922"&gt;QA2D dataset&lt;/a&gt;, which contains the human-annotated declarative sentence for each &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;Q&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;A&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;(Q, A)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathdefault"&gt;Q&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;A&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; pair in SQuAD. &lt;/p&gt;
&lt;h5&gt;Figure 2&lt;/h5&gt;
&lt;p&gt;&lt;img alt="framework" class="img-fluid" src="images/2108/framework.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Our claim generation model.&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Using the Model to Generate Claims&lt;/h3&gt;
&lt;p&gt;Given the pretrained question generator &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;G&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;G&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and the QA-to-Claim model &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;M&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;M&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.10903em;"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, we then formally introduce how we generate claims with different labels. &lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Supported&lt;/em&gt; Claim Generation&lt;/h4&gt;
&lt;p&gt;Given an evidence &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, we use named entity recognition to identify all entities within &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. We treat each identified entity &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;a&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.43056em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as an answer and generate a question &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.19444em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; with the question generator. The question–answer pair &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;(q, a)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; are then sent to the QA-to-Claim model to generate the supported claim &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;c&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;c&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.43056em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. &lt;/p&gt;
&lt;h4&gt;&lt;em&gt;Refuted&lt;/em&gt; Claim Generation&lt;/h4&gt;
&lt;p&gt;To generate a refuted claim, after we generate the question–answer pair &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;(q, a)&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, we use &lt;strong&gt;answer replacement&lt;/strong&gt; to replace the answer &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;a&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.43056em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; with another entity &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo lspace="0em" mathvariant="normal" rspace="0em"&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;a'&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.751892em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.751892em;"&gt;&lt;span style="top:-3.063em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mtight"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; with the same type such that &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo lspace="0em" mathvariant="normal" rspace="0em"&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;a'&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.751892em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.751892em;"&gt;&lt;span style="top:-3.063em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mtight"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; becomes an incorrect answer to the question &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;q&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.625em;vertical-align:-0.19444em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. Using &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;a&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.43056em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as the query, we randomly sample a phrase from the top-5 most similar phrases in the pretrained &lt;a href="https://github.com/explosion/sense2vec"&gt;Sense2Vec&lt;/a&gt; as the replacing answer &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo lspace="0em" mathvariant="normal" rspace="0em"&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;a'&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.751892em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.751892em;"&gt;&lt;span style="top:-3.063em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mtight"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. The new pair &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mo stretchy="false"&gt;(&lt;/mo&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo separator="true"&gt;,&lt;/mo&gt;&lt;msup&gt;&lt;mi&gt;a&lt;/mi&gt;&lt;mo lspace="0em" mathvariant="normal" rspace="0em"&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;mo stretchy="false"&gt;)&lt;/mo&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;(q, a')&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:1.001892em;vertical-align:-0.25em;"&gt;&lt;/span&gt;&lt;span class="mopen"&gt;(&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace" style="margin-right:0.16666666666666666em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.751892em;"&gt;&lt;span style="top:-3.063em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mtight"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose"&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; is then fed to the QA-to-Claim model to generate the refuted claim. &lt;/p&gt;
&lt;h4&gt;&lt;em&gt;NEI&lt;/em&gt; Claim Generation&lt;/h4&gt;
&lt;p&gt;We need to generate a question &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msup&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mo lspace="0em" mathvariant="normal" rspace="0em"&gt;′&lt;/mo&gt;&lt;/msup&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;q'&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.946332em;vertical-align:-0.19444em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault" style="margin-right:0.03588em;"&gt;q&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.751892em;"&gt;&lt;span style="top:-3.063em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mtight"&gt;′&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; which is relevant but cannot be answered by &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. To this end, we link &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; back to its original Wikipedia article &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;W&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and expand the evidence with additional contexts &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P_{ext}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.83333em;vertical-align:-0.15em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.2805559999999999em;"&gt;&lt;span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;e&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;x&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.15em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;, which are five randomly-retrieved sentences from &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;W&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;W&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;W&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; that are not present in &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;. As shown in the example in the above Figure, one additional context retrieved is "By the time the riots ended, 63 people had been killed". We then concatenate &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; and &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P_{ext}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.83333em;vertical-align:-0.15em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.2805559999999999em;"&gt;&lt;span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;e&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;x&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.15em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as the expanded evidence, based on which we generate a supported claim given an entity in &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;msub&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mrow&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;x&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;/mrow&gt;&lt;/msub&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P_{ext}&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.83333em;vertical-align:-0.15em;"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.2805559999999999em;"&gt;&lt;span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"&gt;&lt;span class="pstrut" style="height:2.7em;"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;e&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;x&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;t&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist" style="height:0.15em;"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt; as the answer (e.g., "63"). This results in a claim relevant to but unverifiable by the original evidence &lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;&lt;math xmlns="http://www.w3.org/1998/Math/MathML"&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding="application/x-tex"&gt;P&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span aria-hidden="true" class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut" style="height:0.68333em;vertical-align:0em;"&gt;&lt;/span&gt;&lt;span class="mord mathdefault" style="margin-right:0.13889em;"&gt;P&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;.  &lt;/p&gt;
&lt;h3&gt;Experiments&lt;/h3&gt;
&lt;p&gt;By applying our QACG model to each of the 18,541 Wikipedia articles in the FEVER training set, we generate a total number of 176,370 supported claims, 360,924 refuted claims, and 258,452 NEI claims. &lt;/p&gt;
&lt;h4&gt;Evaluation Datasets&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;FEVER-S/R&lt;/strong&gt;: Since only the supported and refuted claims are labeled with gold evidence in FEVER, we take the claim–evidence pairs of these two classes from the FEVER test set for evaluation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FEVER-Symmetric&lt;/strong&gt;: this is a carefully-designed unbiased test set designed by &lt;a href="https://arxiv.org/abs/1908.05267"&gt;Schuster et al. (2019)&lt;/a&gt; to detect the robustness of the fact verification model. Only supported and refuted claims are present in this test set. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FEVER-S/R/N&lt;/strong&gt;: The full FEVER test set are used for a three-class verification. We use the system of &lt;a href="https://arxiv.org/abs/1901.02534"&gt;Malon (2019)&lt;/a&gt; to retrieve evidence sentences for NEI claims. &lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Zero-shot Fact Verification&lt;/h4&gt;
&lt;p&gt;Models for comparison: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Supervised&lt;/strong&gt;: the RoBERTa-large model fine-tuned on the FEVER training set as the supervised model. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;QACG&lt;/strong&gt;: the RoBERTa-large model fine-tuned on our generated training set. &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Perplexity&lt;/strong&gt;: It predicts the class label based on the perplexity of the claim under a pretrained GPT2 language model, following the assumption that "misinformation has high perplexity". &lt;/li&gt;
&lt;li&gt;&lt;strong&gt;LM as Fact Checker&lt;/strong&gt; &lt;a href="https://arxiv.org/abs/2006.04102"&gt;(Lee et al., 2020b)&lt;/a&gt;: It leverages the implicit knowledge stored in the pretrained BERT language model to verify a claim. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="zero-shot-experiment" class="img-fluid" src="images/2108/zero-shot-experiment.png"&gt;&lt;/p&gt;
&lt;p&gt;QACG attains 78.1 F1 on the FEVER-S/R and 62.6 F1 on the FEVER-S/R/N. Although QACG does not see any human-labelled (evidence, claim) pair in training, the F1 gap to the fully-supervised model is only 17.0 and 15.2 on these two settings, respectively. &lt;strong&gt;The results demonstrate the effectiveness of QACG in generating good (evidence, claim) pairs for training the fact verification model.&lt;/strong&gt; We observe a large performance drop when the supervised model is evaluated on the FEVER-Symmetric test set (−9.6 F1). However, the models trained with our generated data drop only 1.2 and 1.0 F1 drop. This suggests that the wide range of different claims we generate as training data helps eliminate some of the annotation artifacts present in FEVER, leading to a more robust fact verification model. &lt;/p&gt;
&lt;h4&gt;Few-shot Fact Verification&lt;/h4&gt;
&lt;p&gt;The blue solid line in the below Figure shows the F1 scores on FEVER-Symmetric after fine-tuning with different numbers of labeled training data. We compare this with training the model from scratch with the human-labeled data (grey dashed line). Our model performs consistently better than the model without pretraining, regardless of the amount of labeled training data. The improvement is especially prominent in data-poor regimes.  The results show pretraining fact verification with QACG greatly reduces the demand for in-domain humanannotated data. &lt;strong&gt;Our method can provide a "warm start" for fact verification system when applied to a new domain where training data are limited.&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;&lt;img alt="few-shot-fact-verification" class="img-fluid" src="images/2108/few-shot-fact-verification.png"&gt;&lt;/p&gt;
&lt;h4&gt;Case Study&lt;/h4&gt;
&lt;p&gt;The below Table shows representative claims generated by our model. The claims are fluent, label-cohesive, and exhibit encouraging language variety.  However, one limitation is that our generated claims are mostly &lt;strong&gt;lack of deep reasoning over the evidence&lt;/strong&gt;. This is because we finetune the question generator on the SQuAD dataset, in which more than 80% of its questions are shallow factoid questions. &lt;/p&gt;
&lt;p&gt;&lt;img alt="example-claims" class="img-fluid" src="images/2108/example-claims.png"&gt;&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;In this work, we utilize the question generation model to ask different questions for given evidence and convert question–answer pairs into claims with different labels. We show that the generated claims can train a well-performing fact verification model in both the zero-shot and the few-shot learning setting. In summary, our contributions are: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We explore the possibility of automatically &lt;strong&gt;generating large-scale (evidence, claim) pairs&lt;/strong&gt; to train the fact verification model.&lt;/li&gt;
&lt;li&gt;We propose a simple yet general framework &lt;strong&gt;Question Answering for Claim Generation (QACG)&lt;/strong&gt; to generate three types of claims from any given evidence: 1) claims that are &lt;strong&gt;supported&lt;/strong&gt; by the evidence, 2) claims that are &lt;strong&gt;refuted&lt;/strong&gt; by the evidence, and 3) claims that the evidence does &lt;strong&gt;Not have Enough Information (NEI)&lt;/strong&gt; to verify.&lt;/li&gt;
&lt;li&gt;We show that the generated training data can greatly benefit the fact verification system in both &lt;strong&gt;zero-shot and few-shot learning settings&lt;/strong&gt;. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can check out our full paper &lt;a href="https://arxiv.org/pdf/2105.14682.pdf"&gt;here&lt;/a&gt; and our source code/data on &lt;a href="https://github.com/teacherpeterpan/Zero-shot-Fact-Verification"&gt;GitHub&lt;/a&gt;. If you have questions, please feel free to email us.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Liangming Pan: &lt;a href="liangmingpan@u.nus.edu"&gt;liangmingpan@u.nus.edu&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wenhu Chen: &lt;a href="wenhuchen@cs.ucsb.edu"&gt;wenhuchen@cs.ucsb.edu&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;&lt;strong&gt;Acknowledgments&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;This blog post is based on the paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/2105.14682.pdf"&gt;Zero-shot Fact Verification by Claim Generation&lt;/a&gt;. &lt;a href="https://liangmingpan.com/"&gt;Liangming Pan&lt;/a&gt;, &lt;a href="https://wenhuchen.github.io/"&gt;Wenhu Chen&lt;/a&gt;, &lt;a href="https://xwhan.github.io/"&gt;Wenhan Xiong&lt;/a&gt;, &lt;a href="https://www.comp.nus.edu.sg/~kanmy/"&gt;Min-Yen Kan&lt;/a&gt;, and &lt;a href="https://sites.cs.ucsb.edu/~william/"&gt;William Yang Wang&lt;/a&gt;. ACL-IJCNLP 2021. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Many thanks to my collaborators and advisors, Wenhu Chen, Wenhan Xiong, Min-Yen Kan and William Yang Wang for their help. Many thanks to Michael Saxon for edits on this blog post. &lt;/p&gt;</content><category term="ACL 2021"></category><category term="Fact Checking"></category><category term="Question Generation"></category><category term="Claim Generation"></category><category term="Zero-shot Learning"></category></entry></feed>